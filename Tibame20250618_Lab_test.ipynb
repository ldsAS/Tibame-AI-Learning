{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQUG3bmH4GmGUJVpMSydP9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldsAS/Tibame-AI-Learning/blob/main/Tibame20250618_Lab_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzL6NjKk6hIg",
        "outputId": "ccb21528-71ed-4ebb-eff5-132970b4ed40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正在讀取鐵達尼號訓練資料...\n",
            "資料讀取成功！\n",
            "資料前5行：\n",
            "   乘客序號  船票等級                                                 姓名      性別  \\\n",
            "0     1     3                            Braund, Mr. Owen Harris    male   \n",
            "1     2     1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   \n",
            "2     3     3                             Heikkinen, Miss. Laina  female   \n",
            "3     4     1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   \n",
            "4     5     3                           Allen, Mr. William Henry    male   \n",
            "\n",
            "     年紀  旁系親屬數目  直系親屬數目              船票編號     船票價格  船艙號碼 出發港口  是否倖存  \n",
            "0  22.0       1       0         A/5 21171   7.2500   NaN    S     0  \n",
            "1  38.0       1       0          PC 17599  71.2833   C85    C     1  \n",
            "2  26.0       0       0  STON/O2. 3101282   7.9250   NaN    S     1  \n",
            "3  35.0       1       0            113803  53.1000  C123    S     1  \n",
            "4  35.0       0       0            373450   8.0500   NaN    S     0  \n",
            "\n",
            "資料資訊：\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   乘客序號    891 non-null    int64  \n",
            " 1   船票等級    891 non-null    int64  \n",
            " 2   姓名      891 non-null    object \n",
            " 3   性別      891 non-null    object \n",
            " 4   年紀      714 non-null    float64\n",
            " 5   旁系親屬數目  891 non-null    int64  \n",
            " 6   直系親屬數目  891 non-null    int64  \n",
            " 7   船票編號    891 non-null    object \n",
            " 8   船票價格    891 non-null    float64\n",
            " 9   船艙號碼    204 non-null    object \n",
            " 10  出發港口    889 non-null    object \n",
            " 11  是否倖存    891 non-null    int64  \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "\n",
            "將進行預處理的數值型欄位：['年紀', '船票價格']\n",
            "將進行預處理的類別型欄位：['船票等級', '性別', '旁系親屬數目', '直系親屬數目', '出發港口']\n",
            "\n",
            "正在初始化並擬合 AutoPreprocess 預處理器...\n",
            "預處理器擬合完成。\n",
            "正在轉換訓練資料...\n",
            "訓練資料轉換完成。\n",
            "\n",
            "轉換後資料前5行：\n",
            "         年紀      船票價格  船票等級_3  船票等級_1  船票等級_2  性別_male  性別_female  旁系親屬數目_1  \\\n",
            "0  0.271174 -0.502445    True   False   False     True      False      True   \n",
            "1  0.472229  0.786845   False    True   False    False       True      True   \n",
            "2  0.321438 -0.488854    True   False   False    False       True     False   \n",
            "3  0.434531  0.420730   False    True   False    False       True      True   \n",
            "4  0.434531 -0.486337    True   False   False     True      False     False   \n",
            "\n",
            "   旁系親屬數目_0  旁系親屬數目_3  ...  直系親屬數目_1  直系親屬數目_2  直系親屬數目_5  直系親屬數目_3  直系親屬數目_4  \\\n",
            "0     False     False  ...     False     False     False     False     False   \n",
            "1     False     False  ...     False     False     False     False     False   \n",
            "2      True     False  ...     False     False     False     False     False   \n",
            "3     False     False  ...     False     False     False     False     False   \n",
            "4      True     False  ...     False     False     False     False     False   \n",
            "\n",
            "   直系親屬數目_6  出發港口_S  出發港口_C  出發港口_Q  出發港口_nan  \n",
            "0     False    True   False   False     False  \n",
            "1     False   False    True   False     False  \n",
            "2     False    True   False   False     False  \n",
            "3     False    True   False   False     False  \n",
            "4     False    True   False   False     False  \n",
            "\n",
            "[5 rows x 25 columns]\n",
            "\n",
            "轉換後資料資訊：\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 25 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   年紀         891 non-null    float64\n",
            " 1   船票價格       891 non-null    float64\n",
            " 2   船票等級_3     891 non-null    bool   \n",
            " 3   船票等級_1     891 non-null    bool   \n",
            " 4   船票等級_2     891 non-null    bool   \n",
            " 5   性別_male    891 non-null    bool   \n",
            " 6   性別_female  891 non-null    bool   \n",
            " 7   旁系親屬數目_1   891 non-null    bool   \n",
            " 8   旁系親屬數目_0   891 non-null    bool   \n",
            " 9   旁系親屬數目_3   891 non-null    bool   \n",
            " 10  旁系親屬數目_4   891 non-null    bool   \n",
            " 11  旁系親屬數目_2   891 non-null    bool   \n",
            " 12  旁系親屬數目_5   891 non-null    bool   \n",
            " 13  旁系親屬數目_8   891 non-null    bool   \n",
            " 14  直系親屬數目_0   891 non-null    bool   \n",
            " 15  直系親屬數目_1   891 non-null    bool   \n",
            " 16  直系親屬數目_2   891 non-null    bool   \n",
            " 17  直系親屬數目_5   891 non-null    bool   \n",
            " 18  直系親屬數目_3   891 non-null    bool   \n",
            " 19  直系親屬數目_4   891 non-null    bool   \n",
            " 20  直系親屬數目_6   891 non-null    bool   \n",
            " 21  出發港口_S     891 non-null    bool   \n",
            " 22  出發港口_C     891 non-null    bool   \n",
            " 23  出發港口_Q     891 non-null    bool   \n",
            " 24  出發港口_nan   891 non-null    bool   \n",
            "dtypes: bool(23), float64(2)\n",
            "memory usage: 34.1 KB\n",
            "\n",
            "--- 預處理完成，接下來是模型訓練步驟 ---\n",
            "在資料預處理完成後，下一步通常是：\n",
            "1. 選擇一個適合的機器學習模型（例如：邏輯迴歸、決策樹、隨機森林等）。\n",
            "2. 使用 `X_train_processed` 作為特徵，`y_train` 作為目標變數來訓練模型。\n",
            "3. 評估模型的性能。\n",
            "4. 如果有測試資料，使用相同的 `auto_preprocess` 實例來轉換測試資料，然後用訓練好的模型進行預測。\n",
            "\n",
            "預處理器已儲存至：titanic_auto_preprocess.pkl\n"
          ]
        }
      ],
      "source": [
        "# 鐵達尼號乘客資料預處理與模型準備\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "class AutoPreprocess:\n",
        "    def __init__(self):\n",
        "        self.scaler = {}\n",
        "        self.fillna_value = {}\n",
        "        self.onehotencode_value = {}\n",
        "        self.columns_order = None # 用於儲存訓練時的欄位順序\n",
        "\n",
        "    def fit(self, df, numeric_cols=None, category_cols=None, fillna_strategy='mean'):\n",
        "        \"\"\"\n",
        "        學習資料的預處理參數。\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): 訓練資料。\n",
        "            numeric_cols (list): 需要標準化的數值型欄位。\n",
        "            category_cols (list): 需要進行獨熱編碼的類別型欄位。\n",
        "            fillna_strategy (str): 數值型欄位的缺失值填充策略 ('mean' 或 'median')。\n",
        "        \"\"\"\n",
        "        self.columns_order = df.columns.tolist() # 儲存原始欄位順序\n",
        "\n",
        "        # 處理數值型欄位\n",
        "        if numeric_cols:\n",
        "            for col in numeric_cols:\n",
        "                if col in df.columns:\n",
        "                    if fillna_strategy == 'mean':\n",
        "                        self.fillna_value[col] = df[col].mean()\n",
        "                    elif fillna_strategy == 'median':\n",
        "                        self.fillna_value[col] = df[col].median()\n",
        "                    else:\n",
        "                        self.fillna_value[col] = 0 # 預設填充為0，你也可以根據需求調整\n",
        "\n",
        "                    # 填充缺失值後再擬合Scaler\n",
        "                    temp_col = df[col].fillna(self.fillna_value[col]).values.reshape(-1, 1)\n",
        "                    scaler = StandardScaler() if col == '船票價格' else MinMaxScaler() # '船票價格' 使用 StandardScaler，其他數值欄位使用 MinMaxScaler\n",
        "                    scaler.fit(temp_col)\n",
        "                    self.scaler[col] = scaler\n",
        "                else:\n",
        "                    print(f\"Warning: Numeric column '{col}' not found in DataFrame.\")\n",
        "\n",
        "        # 處理類別型欄位\n",
        "        if category_cols:\n",
        "            for col in category_cols:\n",
        "                if col in df.columns:\n",
        "                    # 獨熱編碼會自動處理缺失值為一個新的類別\n",
        "                    # 我們只需要記錄訓練集中的所有類別，以確保測試集有一致的欄位\n",
        "                    self.onehotencode_value[col] = df[col].astype(str).unique().tolist()\n",
        "                else:\n",
        "                    print(f\"Warning: Category column '{col}' not found in DataFrame.\")\n",
        "\n",
        "\n",
        "    def transform(self, df):\n",
        "        \"\"\"\n",
        "        根據已學習的參數轉換資料。\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): 需要轉換的資料。\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: 轉換後的資料。\n",
        "        \"\"\"\n",
        "        transformed_df = df.copy()\n",
        "\n",
        "        # 填充缺失值並標準化數值型欄位\n",
        "        for col, scaler in self.scaler.items():\n",
        "            if col in transformed_df.columns:\n",
        "                if col in self.fillna_value:\n",
        "                    transformed_df[col] = transformed_df[col].fillna(self.fillna_value[col])\n",
        "                transformed_df[col] = scaler.transform(transformed_df[col].values.reshape(-1, 1))\n",
        "            else:\n",
        "                print(f\"Warning: Numeric column '{col}' not found in DataFrame during transform. Skipping scaling.\")\n",
        "\n",
        "\n",
        "        # 獨熱編碼類別型欄位\n",
        "        for col, categories in self.onehotencode_value.items():\n",
        "            if col in transformed_df.columns:\n",
        "                # 將新類別轉換為字符串，確保與訓練集類別類型一致\n",
        "                transformed_df[col] = transformed_df[col].astype(str)\n",
        "                # 對於測試集中可能出現的訓練集中不存在的類別，使用 handle_unknown='ignore'\n",
        "                # 或者，更穩健的做法是確保所有類別都存在，這裡我們直接用 pd.get_dummies\n",
        "                # 並且在訓練時記錄所有類別，在轉換時將其傳入\n",
        "                dummy_cols = pd.get_dummies(transformed_df[col], prefix=col)\n",
        "                # 確保轉換後的 df 包含訓練時的類別所有列，如果某些類別在轉換集中不存在，則補0\n",
        "                for cat in categories:\n",
        "                    dummy_col_name = f\"{col}_{cat}\"\n",
        "                    if dummy_col_name not in dummy_cols.columns:\n",
        "                        dummy_cols[dummy_col_name] = 0\n",
        "                transformed_df = pd.concat([transformed_df.drop(columns=[col]), dummy_cols], axis=1)\n",
        "            else:\n",
        "                print(f\"Warning: Category column '{col}' not found in DataFrame during transform. Skipping one-hot encoding.\")\n",
        "\n",
        "\n",
        "        # 重新排序欄位以匹配訓練時的順序\n",
        "        # 這一步很重要，因為模型的特徵順序必須一致\n",
        "        if self.columns_order:\n",
        "            # 獲取原始數據框中非獨熱編碼的欄位\n",
        "            original_non_onehot_cols = [col for col in self.columns_order if col not in self.onehotencode_value]\n",
        "\n",
        "            # 獲取獨熱編碼後的欄位名稱\n",
        "            onehot_encoded_cols = []\n",
        "            for col in self.onehotencode_value:\n",
        "                for category in self.onehotencode_value[col]:\n",
        "                    onehot_encoded_cols.append(f\"{col}_{category}\")\n",
        "\n",
        "            # 合併所有預期的欄位順序，並確保它們都在 transformed_df 中\n",
        "            final_columns_order = []\n",
        "            for col in original_non_onehot_cols:\n",
        "                if col in transformed_df.columns:\n",
        "                    final_columns_order.append(col)\n",
        "            for col in onehot_encoded_cols:\n",
        "                if col in transformed_df.columns:\n",
        "                    final_columns_order.append(col)\n",
        "                else:\n",
        "                    # 如果訓練時存在的獨熱編碼欄位在轉換時不存在，則添加並填充0\n",
        "                    transformed_df[col] = 0\n",
        "                    final_columns_order.append(col) # 確保它在排序中\n",
        "\n",
        "            # 過濾掉那些原始數據框中不存在的欄位，例如 '姓名', '船票編號', '船艙號碼'\n",
        "            final_columns_order = [col for col in final_columns_order if col in transformed_df.columns]\n",
        "\n",
        "            # 確保 '是否倖存' 列（如果存在）在轉換過程中不被排序，或者根據需求處理\n",
        "            if '是否倖存' in transformed_df.columns and '是否倖存' not in final_columns_order:\n",
        "                # 假設 '是否倖存' 是目標變數，通常不會對它進行預處理\n",
        "                # 我們可以把它暫時移除，排序其他特徵，然後再加回來\n",
        "                survived_col = transformed_df['是否倖存']\n",
        "                transformed_df = transformed_df.drop(columns=['是否倖存'])\n",
        "                transformed_df = transformed_df[final_columns_order]\n",
        "                transformed_df['是否倖存'] = survived_col\n",
        "            else:\n",
        "                transformed_df = transformed_df[final_columns_order]\n",
        "\n",
        "\n",
        "        return transformed_df\n",
        "\n",
        "    def save(self, filepath):\n",
        "        \"\"\"儲存預處理器狀態\"\"\"\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, filepath):\n",
        "        \"\"\"載入預處理器狀態\"\"\"\n",
        "        with open(filepath, 'rb') as f:\n",
        "            return pickle.load(f)\n",
        "\n",
        "# --- 開始鐵達尼號資料預處理 ---\n",
        "\n",
        "# 1. 讀取資料\n",
        "print(\"正在讀取鐵達尼號訓練資料...\")\n",
        "try:\n",
        "    df_train = pd.read_csv('Titanic(鐵達尼號乘客)_Train.csv')\n",
        "    print(\"資料讀取成功！\")\n",
        "    print(\"資料前5行：\")\n",
        "    print(df_train.head())\n",
        "    print(\"\\n資料資訊：\")\n",
        "    df_train.info()\n",
        "except FileNotFoundError:\n",
        "    print(\"錯誤：找不到 'Titanic(鐵達尼號乘客)_Train.csv' 檔案。請確認檔案路徑是否正確。\")\n",
        "    # 如果找不到檔案，停止執行後續程式碼\n",
        "    # exit() # 在Colab Notebook中不建議使用exit()，會停止整個Notebook的運行\n",
        "\n",
        "# 2. 定義特徵和目標變數\n",
        "# '是否倖存' 是我們的目標變數\n",
        "target = '是否倖存'\n",
        "# 移除不需要的欄位：'是否倖存', '乘客序號', '姓名', '船票編號', '船艙號碼'\n",
        "features_to_drop = [target, '乘客序號', '姓名', '船票編號', '船艙號碼']\n",
        "# 過濾出實際存在於df_train.columns中的欄位進行drop\n",
        "existing_features_to_drop = [col for col in features_to_drop if col in df_train.columns]\n",
        "features = df_train.drop(columns=existing_features_to_drop).columns.tolist()\n",
        "\n",
        "\n",
        "# 根據鐵達尼號資料的特性，定義數值型和類別型欄位\n",
        "# '年紀' 和 '船票價格' 是數值型，需要填充缺失值和標準化\n",
        "# '船票等級', '性別', '旁系親屬數目', '直系親屬數目', '出發港口' 是類別型，需要獨熱編碼\n",
        "numeric_cols = ['年紀', '船票價格']\n",
        "category_cols = ['船票等級', '性別', '旁系親屬數目', '直系親屬數目', '出發港口']\n",
        "\n",
        "# 確保所有選擇的欄位都存在於資料中\n",
        "numeric_cols = [col for col in numeric_cols if col in features]\n",
        "category_cols = [col for col in category_cols if col in features]\n",
        "\n",
        "print(f\"\\n將進行預處理的數值型欄位：{numeric_cols}\")\n",
        "print(f\"將進行預處理的類別型欄位：{category_cols}\")\n",
        "\n",
        "# 3. 使用 AutoPreprocess 進行預處理\n",
        "print(\"\\n正在初始化並擬合 AutoPreprocess 預處理器...\")\n",
        "auto_preprocess = AutoPreprocess()\n",
        "\n",
        "# 將目標變數從特徵中移除，因為預處理器只處理特徵\n",
        "# 這裡我們已經在前面drop的時候移除了target，所以X_train就是features\n",
        "X_train = df_train[features]\n",
        "y_train = df_train[target] # 目標變數通常不進行預處理，直接用於模型訓練\n",
        "\n",
        "# 擬合預處理器\n",
        "auto_preprocess.fit(X_train, numeric_cols=numeric_cols, category_cols=category_cols, fillna_strategy='mean')\n",
        "print(\"預處理器擬合完成。\")\n",
        "\n",
        "# 轉換訓練資料\n",
        "print(\"正在轉換訓練資料...\")\n",
        "X_train_processed = auto_preprocess.transform(X_train)\n",
        "print(\"訓練資料轉換完成。\")\n",
        "print(\"\\n轉換後資料前5行：\")\n",
        "print(X_train_processed.head())\n",
        "print(\"\\n轉換後資料資訊：\")\n",
        "X_train_processed.info()\n",
        "\n",
        "# 4. 模型訓練（下一步）\n",
        "print(\"\\n--- 預處理完成，接下來是模型訓練步驟 ---\")\n",
        "print(\"在資料預處理完成後，下一步通常是：\")\n",
        "print(\"1. 選擇一個適合的機器學習模型（例如：邏輯迴歸、決策樹、隨機森林等）。\")\n",
        "print(\"2. 使用 `X_train_processed` 作為特徵，`y_train` 作為目標變數來訓練模型。\")\n",
        "print(\"3. 評估模型的性能。\")\n",
        "print(\"4. 如果有測試資料，使用相同的 `auto_preprocess` 實例來轉換測試資料，然後用訓練好的模型進行預測。\")\n",
        "\n",
        "# 範例：儲存預處理器以供未來使用\n",
        "preprocess_filepath = 'titanic_auto_preprocess.pkl'\n",
        "auto_preprocess.save(preprocess_filepath)\n",
        "print(f\"\\n預處理器已儲存至：{preprocess_filepath}\")\n",
        "\n",
        "# 範例：載入預處理器\n",
        "# loaded_preprocess = AutoPreprocess.load(preprocess_filepath)\n",
        "# print(f\"預處理器已從 {preprocess_filepath} 載入。\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 接續前一個程式碼的執行 ---\n",
        "\n",
        "# 導入必要的機器學習函式庫\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"\\n--- 開始模型訓練階段 ---\")\n",
        "\n",
        "# 1. 訓練/測試資料分割\n",
        "# 將預處理後的訓練資料 X_train_processed 和目標變數 y_train 分割成訓練集和驗證集。\n",
        "# test_size=0.2 表示 20% 的資料用於驗證，80% 用於訓練。\n",
        "# random_state 確保每次運行時分割的結果都相同，以便於重現。\n",
        "print(\"正在將資料分割為訓練集和驗證集 (80/20)...\")\n",
        "X_train_model, X_val_model, y_train_model, y_val_model = train_test_split(\n",
        "    X_train_processed, y_train, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"訓練集特徵形狀: {X_train_model.shape}\")\n",
        "print(f\"驗證集特徵形狀: {X_val_model.shape}\")\n",
        "print(f\"訓練集目標形狀: {y_train_model.shape}\")\n",
        "print(f\"驗證集目標形狀: {y_val_model.shape}\")\n",
        "\n",
        "# 2. 選擇和訓練模型\n",
        "# 使用邏輯迴歸模型。\n",
        "# solver='liblinear' 是一個常用的優化算法，對於小型數據集效果良好。\n",
        "# random_state 確保模型訓練過程的隨機性部分可重現。\n",
        "print(\"\\n正在初始化並訓練邏輯迴歸模型...\")\n",
        "# model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train_model, y_train_model)\n",
        "print(\"模型訓練完成。\")\n",
        "\n",
        "# 3. 模型評估\n",
        "# 使用驗證集進行預測。\n",
        "print(\"\\n正在使用驗證集評估模型性能...\")\n",
        "y_pred = model.predict(X_val_model)\n",
        "\n",
        "# 計算準確度\n",
        "accuracy = accuracy_score(y_val_model, y_pred)\n",
        "print(f\"模型在驗證集上的準確度: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\n--- 模型訓練和評估完成 ---\")\n",
        "print(\"你可以嘗試不同的模型或調整模型參數，以尋找更好的性能。\")\n",
        "print(\"例如：隨機森林、梯度提升樹等。\")\n",
        "\n",
        "# 範例：儲存訓練好的模型\n",
        "model_filepath = 'model.pkl'\n",
        "with open(model_filepath, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print(f\"\\n訓練好的模型已儲存至：{model_filepath}\")\n",
        "\n",
        "# 範例：載入訓練好的模型\n",
        "# loaded_model = None\n",
        "# with open(model_filepath, 'rb') as f:\n",
        "#     loaded_model = pickle.load(f)\n",
        "# print(f\"模型已從 {model_filepath} 載入。\")\n",
        "\n",
        "# # 載入後的模型可以再次用於預測\n",
        "# # example_prediction = loaded_model.predict(some_new_processed_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yennvpRB97bz",
        "outputId": "52375198-4c29-47f8-9a10-2463e72399da"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 開始模型訓練階段 ---\n",
            "正在將資料分割為訓練集和驗證集 (80/20)...\n",
            "訓練集特徵形狀: (712, 25)\n",
            "驗證集特徵形狀: (179, 25)\n",
            "訓練集目標形狀: (712,)\n",
            "驗證集目標形狀: (179,)\n",
            "\n",
            "正在初始化並訓練邏輯迴歸模型...\n",
            "模型訓練完成。\n",
            "\n",
            "正在使用驗證集評估模型性能...\n",
            "模型在驗證集上的準確度: 0.8045\n",
            "\n",
            "--- 模型訓練和評估完成 ---\n",
            "你可以嘗試不同的模型或調整模型參數，以尋找更好的性能。\n",
            "例如：隨機森林、梯度提升樹等。\n",
            "\n",
            "訓練好的模型已儲存至：model.pkl\n"
          ]
        }
      ]
    }
  ]
}