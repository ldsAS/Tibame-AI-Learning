{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldsAS/Tibame-AI-Learning/blob/main/Tibame20250612_%E9%9B%86%E6%88%90%E6%96%B9%E6%B3%95_Ensemble_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0146309",
      "metadata": {
        "id": "a0146309"
      },
      "source": [
        "# Ensemble Method（集成方法）\n",
        "\n",
        "Ensemble Method（集成方法）是機器學習中的一種技術，旨在通過結合多個基礎模型（稱為弱學習器）來提高整體的預測性能。這些基礎模型通常是同質的，即它們使用相同的學習算法，或者是異質的，即使用不同的學習算法。集成方法通過結合多個模型的預測結果，從而減少過擬合的風險、提高準確度，並增加穩定性。\n",
        "\n",
        "## 常見的集成方法包括：\n",
        "\n",
        "- Bagging（Bootstrap Aggregating）\n",
        "    - 這種方法通過隨機抽樣的方式創建多個訓練集，並訓練多個模型，最終的預測結果通常是這些模型預測的平均或投票結果。\n",
        "    - **隨機森林（Random Forest）** 是 Bagging 方法的一個例子。  \n",
        "- Boosting\n",
        "    - Boosting 旨在通過逐步構建一系列模型，其中每一個後續模型都試圖修正前一個模型的錯誤。最終的預測結果是所有模型預測的加權平均。\n",
        "    - 常見的 Boosting 算法包括 **AdaBoost**、**Gradient Boosting**、**XGBoost** 等。  \n",
        "- Stacking（堆疊）\n",
        "    - Stacking 是將多個不同類型的模型的預測結果作為特徵，並通過另一個模型（通常稱為 meta-model）進行最終預測的過程。這種方法可以有效地融合不同模型的優勢。\n",
        "\n",
        "## 優點\n",
        "\n",
        "- **提高準確度**：\n",
        "    通過集成多個模型，能夠減少單一模型的偏差和方差，提高預測的準確度。\n",
        "- **減少過擬合**：\n",
        "    特別是在 Bagging 和 Boosting 方法中，通過結合多個模型的預測結果，減少單一模型過擬合的風險。\n",
        "- **穩定性更高**：\n",
        "    集成方法比單一模型對噪聲和數據變異的敏感度低，通常具有更高的穩定性。\n",
        "- **處理複雜問題**：\n",
        "    通過使用多個不同的學習器來解決複雜的預測問題，能夠利用每個模型的優勢。\n",
        "\n",
        "## 缺點\n",
        "- **計算成本較高**：\n",
        "    訓練多個模型會增加計算開銷和訓練時間，特別是在大規模數據集上。\n",
        "- **解釋性差**：\n",
        "    集成方法通常難以解釋，因為多個模型的結果是綜合起來的，很難直接理解模型的內部決策過程。\n",
        "- **需要更多的內存和存儲空間**：\n",
        "    需要存儲多個模型，對於資源有限的情況可能不適用。\n",
        "- **難以調參**：\n",
        "    集成方法通常涉及多個模型，每個模型都可能有不同的超參數，調整這些參數可能較為繁瑣。\n",
        "\n",
        "集成方法能夠有效地提高預測性能，減少過擬合的風險，但需要更多的計算資源並且缺乏解釋性。它在許多實際應用中都能發揮重要作用，特別是在需要高準確度的問題領域。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a66bcf40",
      "metadata": {
        "id": "a66bcf40"
      },
      "source": [
        "## 載入資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4000d781",
      "metadata": {
        "id": "4000d781"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv(\"../data/R公司_人員資料_train.csv\")\n",
        "\n",
        "input_field = ['性別(Gender)', '年齡(Age)', '是否為成年人(Over18)',\n",
        "       '婚姻狀態(MaritalStatus)', '通勤距離(DistanceFromHome)', '教育程度(Education)',\n",
        "       '教育專業領域(EducationField)', '部門(Department)', '職位名稱(JobRole)',\n",
        "       '職位等級(JobLevel)', '在該公司工作總年資(YearsAtCompany)',\n",
        "       '在該職位工作年資(YearsInCurrentRole)', '在該職等工作年資(YearsSinceLastPromotion)',\n",
        "       '與現任管理者工作年資(YearsWithCurrManager)', '總工作年資(TotalWorkingYears)',\n",
        "       '過去工作公司家數(NumCompaniesWorked)', '每日工資額(DailyRate)',\n",
        "       '每小時工資額(HourlyRate)', '月收入(MonthlyIncome)', '月費率(MonthlyRate)',\n",
        "       '標準工作時間(StandardHours)', '加班(OverTime)', '調薪百分比(PercentSalaryHike)',\n",
        "       '股票選擇權等級(StockOptionLevel)', '績效評估(PerformanceRating)',\n",
        "       '出差頻率(BusinessTravel)', '去年訓練時間(TrainingTimesLastYear)',\n",
        "       '工作滿意度(JobSatisfaction)', '工作環境滿意度(EnvironmentSatisfaction)',\n",
        "       '工作投入(JobInvolvement)', '工作生活平衡(WorkLifeBalance)',\n",
        "       '人際關係滿意度(RelationshipSatisfaction)']\n",
        "target_field = '離職(Attrition)'\n",
        "target_filed_map = {\"Yes\": 1, \"No\": 0}\n",
        "\n",
        "data_input = data[input_field]\n",
        "data_target = data[target_field].map(target_filed_map)\n",
        "\n",
        "data_input = pd.get_dummies(data_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a29ecba0",
      "metadata": {
        "id": "a29ecba0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "def run_cv(model):\n",
        "    score_type = ['balanced_accuracy','roc_auc']\n",
        "    cv_scores = cross_validate(model, data_input, data_target, cv=5, n_jobs=5, return_train_score=True, scoring=score_type)\n",
        "    for key in cv_scores:\n",
        "        print(key,' : ', cv_scores[key].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60e47f07",
      "metadata": {
        "id": "60e47f07"
      },
      "source": [
        "# Decision Tree\n",
        "Base Line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd774b9e",
      "metadata": {
        "id": "cd774b9e",
        "outputId": "79d5bc2b-7b4f-4f68-bb12-0ee9bfa4b989"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.011723041534423828\n",
            "score_time  :  0.00440821647644043\n",
            "test_balanced_accuracy  :  0.5987009419152276\n",
            "train_balanced_accuracy  :  1.0\n",
            "test_roc_auc  :  0.5987009419152276\n",
            "train_roc_auc  :  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a86f55b",
      "metadata": {
        "id": "6a86f55b"
      },
      "source": [
        "# Bagging\n",
        "**Bagging**（Bootstrap Aggregating）是一種集成學習（Ensemble Learning）技術，旨在通過將多個模型的預測結果進行結合來提高預測的準確性和穩定性。它的基本思想是通過對訓練資料進行重複抽樣，生成多個訓練子集，並基於這些子集訓練多個模型，最後將這些模型的預測結果進行結合，從而減少過擬合的風險。\n",
        "\n",
        "## Bagging的主要特點：\n",
        "\n",
        "1. **重複抽樣（Bootstrap Sampling）**\n",
        "   - Bagging通過對原始訓練資料進行有放回的隨機抽樣，生成多個不同的訓練子集。每個子集可能包含重複的樣本，這樣可以增加訓練數據的多樣性。\n",
        "2. **多模型訓練**\n",
        "   - 在每個訓練子集上，訓練一個基礎模型。這些基礎模型通常是獨立且相同的，例如決策樹（也就是隨機森林中的基礎決策樹）。\n",
        "3. **結果聚合**\n",
        "   - 在預測階段，對所有基礎模型的預測結果進行聚合。對於分類問題，通常使用**投票法**（majority voting）；對於回歸問題，則使用**平均法**。\n",
        "4. **減少過擬合**\n",
        "   - 由於每個模型在不同的數據子集上訓練，這樣可以減少模型對特定訓練數據的過擬合，從而提升模型的泛化能力。\n",
        "\n",
        "## Bagging的優勢：\n",
        "- **降低方差**：Bagging減少了單個模型的方差，通常會得到更穩定的預測結果。\n",
        "- **提高預測準確度**：通過集成多個模型的預測，Bagging能夠提高預測的準確度，尤其是對於高方差的基礎模型（如決策樹）。\n",
        "- **並行化**：由於每個基礎模型都是獨立訓練的，因此Bagging算法可以輕鬆進行並行計算，從而提高訓練效率。\n",
        "\n",
        "## 常見的Bagging算法：\n",
        "- **隨機森林（Random Forest）**：隨機森林是Bagging的延伸，利用多棵隨機選擇特徵的決策樹來進行預測，進一步增加模型的多樣性並降低過擬合。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8648cc8e",
      "metadata": {
        "id": "8648cc8e"
      },
      "source": [
        "## BaggingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c60274",
      "metadata": {
        "id": "05c60274",
        "outputId": "cc48d09b-80a7-432e-8eb9-818f4e51c943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.11075596809387207\n",
            "score_time  :  0.011260986328125\n",
            "test_balanced_accuracy  :  0.613770277341706\n",
            "train_balanced_accuracy  :  0.9532561101823103\n",
            "test_roc_auc  :  0.7556036760858189\n",
            "train_roc_auc  :  0.9994733931552358\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "model = BaggingClassifier(n_estimators=10)\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9b961a4",
      "metadata": {
        "id": "e9b961a4",
        "outputId": "86f69cac-3bdd-41a3-b47a-72d46610a0c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.13799672126770018\n",
            "score_time  :  0.014586639404296876\n",
            "test_balanced_accuracy  :  0.6126648351648353\n",
            "train_balanced_accuracy  :  0.960843085741581\n",
            "test_roc_auc  :  0.7572474489795917\n",
            "train_roc_auc  :  0.9995636953249118\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = BaggingClassifier(DecisionTreeClassifier())\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93c3fad",
      "metadata": {
        "id": "e93c3fad"
      },
      "source": [
        "## RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec9411e",
      "metadata": {
        "id": "1ec9411e",
        "outputId": "7f70e806-9f1c-4094-d6ec-ba4b68dd35fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.33660049438476564\n",
            "score_time  :  0.028206348419189453\n",
            "test_balanced_accuracy  :  0.596361852433281\n",
            "train_balanced_accuracy  :  1.0\n",
            "test_roc_auc  :  0.8105625327053898\n",
            "train_roc_auc  :  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5b6fe07",
      "metadata": {
        "id": "e5b6fe07"
      },
      "source": [
        "### RandomForest 內建欄位關鍵度評估"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074deb2b",
      "metadata": {
        "id": "074deb2b",
        "outputId": "6f512b48-f0f7-4631-ecf3-44ffd1e36650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "年齡(Age)  =  0.056808296978834785\n",
            "通勤距離(DistanceFromHome)  =  0.0405274073692964\n",
            "教育程度(Education)  =  0.019360681915986905\n",
            "職位等級(JobLevel)  =  0.02542443834946225\n",
            "在該公司工作總年資(YearsAtCompany)  =  0.040434580813888066\n",
            "在該職位工作年資(YearsInCurrentRole)  =  0.03278910941256539\n",
            "在該職等工作年資(YearsSinceLastPromotion)  =  0.025887071381549772\n",
            "與現任管理者工作年資(YearsWithCurrManager)  =  0.025941708470322452\n",
            "總工作年資(TotalWorkingYears)  =  0.044637131697863576\n",
            "過去工作公司家數(NumCompaniesWorked)  =  0.0339400203501874\n",
            "每日工資額(DailyRate)  =  0.0436188772005599\n",
            "每小時工資額(HourlyRate)  =  0.041361278878690025\n",
            "月收入(MonthlyIncome)  =  0.08070266493671623\n",
            "月費率(MonthlyRate)  =  0.04273308846444309\n",
            "標準工作時間(StandardHours)  =  0.0\n",
            "調薪百分比(PercentSalaryHike)  =  0.0304369841029324\n",
            "股票選擇權等級(StockOptionLevel)  =  0.026101635039405154\n",
            "績效評估(PerformanceRating)  =  0.0033256282336598776\n",
            "去年訓練時間(TrainingTimesLastYear)  =  0.022876698187359185\n",
            "工作滿意度(JobSatisfaction)  =  0.02544019761631164\n",
            "工作環境滿意度(EnvironmentSatisfaction)  =  0.02409725059309701\n",
            "工作投入(JobInvolvement)  =  0.02287386587201727\n",
            "工作生活平衡(WorkLifeBalance)  =  0.01985236493584872\n",
            "人際關係滿意度(RelationshipSatisfaction)  =  0.021025464258038317\n",
            "性別(Gender)_Female  =  0.008266323310212355\n",
            "性別(Gender)_Male  =  0.008509855056555712\n",
            "是否為成年人(Over18)_Y  =  0.0\n",
            "婚姻狀態(MaritalStatus)_Divorced  =  0.005783638350503019\n",
            "婚姻狀態(MaritalStatus)_Married  =  0.008933962813433819\n",
            "婚姻狀態(MaritalStatus)_Single  =  0.01988929851541183\n",
            "教育專業領域(EducationField)_Human Resources  =  0.0019218918253492237\n",
            "教育專業領域(EducationField)_Life Sciences  =  0.00616073336408588\n",
            "教育專業領域(EducationField)_Marketing  =  0.005735668497607651\n",
            "教育專業領域(EducationField)_Medical  =  0.007867382517302438\n",
            "教育專業領域(EducationField)_Other  =  0.0029664370264008626\n",
            "教育專業領域(EducationField)_Technical Degree  =  0.007775291453869681\n",
            "部門(Department)_Human Resources  =  0.002232456069175841\n",
            "部門(Department)_Research & Development  =  0.007943744927060431\n",
            "部門(Department)_Sales  =  0.009752407522977189\n",
            "職位名稱(JobRole)_Healthcare Representative  =  0.0015680837109250494\n",
            "職位名稱(JobRole)_Human Resources  =  0.0032159073835595344\n",
            "職位名稱(JobRole)_Laboratory Technician  =  0.010297983019026487\n",
            "職位名稱(JobRole)_Manager  =  0.0022123678835439817\n",
            "職位名稱(JobRole)_Manufacturing Director  =  0.0019524275101828472\n",
            "職位名稱(JobRole)_Research Director  =  0.0009842718646855375\n",
            "職位名稱(JobRole)_Research Scientist  =  0.006570416102319377\n",
            "職位名稱(JobRole)_Sales Executive  =  0.006613425103407776\n",
            "職位名稱(JobRole)_Sales Representative  =  0.008288550160863377\n",
            "加班(OverTime)_No  =  0.04474172357421975\n",
            "加班(OverTime)_Yes  =  0.03393255608958807\n",
            "出差頻率(BusinessTravel)_Non-Travel  =  0.0037377466038468494\n",
            "出差頻率(BusinessTravel)_Travel_Frequently  =  0.01302972047104623\n",
            "出差頻率(BusinessTravel)_Travel_Rarely  =  0.008919284213803213\n"
          ]
        }
      ],
      "source": [
        "model.fit(data_input, data_target)\n",
        "importances = model.feature_importances_\n",
        "feature_names = model.feature_names_in_\n",
        "\n",
        "for i in range(0,len(importances)):\n",
        "    print(feature_names[i], ' = ',importances[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "254830f4",
      "metadata": {
        "id": "254830f4",
        "outputId": "e3f3eeae-383f-416a-8ae2-27bdfb8d953a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.9999999999999999)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#重要性的總合為1\n",
        "importances.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e2c7e5d",
      "metadata": {
        "id": "4e2c7e5d"
      },
      "source": [
        "# Boost\n",
        "**Boost**（提升）是指一類用於提升模型性能的機器學習方法，通常以集成學習（Ensemble Learning）為基礎，通過將多個弱學習器結合成一個強學習器來提高預測準確度。Boosting方法會重點處理那些在前一輪中錯誤預測的樣本，從而使得模型對難以分類的樣本有更好的識別能力。\n",
        "\n",
        "## Boost的主要特點：\n",
        "1. **加強難以分類的樣本**\n",
        "   - Boosting的基本思想是對於每一輪訓練，根據前一輪模型的預測結果調整樣本的權重。錯誤預測的樣本會被賦予更高的權重，這樣在下一輪訓練時，模型會更加關注這些錯誤樣本。\n",
        "2. **基於弱學習器的集成**\n",
        "   - Boosting通常使用弱學習器（例如簡單的決策樹）作為基礎學習器。這些弱學習器的表現可能較差，但通過加強和集成多個模型，最終能得到較強的預測能力。\n",
        "3. **加法模型**\n",
        "   - 在Boosting過程中，每一輪的模型預測結果會加到之前的模型上，最終的預測是所有基礎模型預測結果的加權和。\n",
        "4. **強化學習的準確性**\n",
        "   - 通過多輪迭代和加權，Boosting能夠逐漸提升模型的準確度，特別是在處理復雜或不平衡數據集時。\n",
        "\n",
        "## Boost的常見算法：\n",
        "1. **AdaBoost（Adaptive Boosting）**\n",
        "   - AdaBoost是最早的Boosting算法之一。在每一輪中，它會根據前一輪錯誤的樣本，調整樣本的權重，使得下一輪模型更加關注這些錯誤的樣本。最終的預測是所有弱學習器預測結果的加權和。\n",
        "2. **Gradient Boosting**\n",
        "   - Gradient Boosting（梯度提升）是一種基於梯度下降的Boosting算法。它通過每次選擇一個新的模型來減少當前模型的誤差，這些模型是基於負梯度方向進行擬合的。\n",
        "3. **XGBoost**\n",
        "   - XGBoost是Gradient Boosting的一個高效實現，具有更多的優化和正則化選項，能處理缺失值並且能有效避免過擬合，是目前最流行的Boosting算法之一。\n",
        "4. **LightGBM**\n",
        "   - LightGBM（Light Gradient Boosting Machine）是一個高效的梯度提升算法，主要通過優化樹結構和採用直方圖算法來加速模型訓練，特別適合大規模數據。\n",
        "\n",
        "## Boost的優勢：\n",
        "- **提高準確度**：通過加強錯誤樣本的學習，Boosting方法通常能顯著提高模型的預測準確度。\n",
        "- **有效處理不平衡數據**：Boosting能夠更好地處理類別不平衡的問題，尤其是當一些類別的樣本較少時。\n",
        "- **強化模型的表現**：即使是表現不佳的基礎學習器，在Boosting的加持下，最終也能達到較高的預測效果。\n",
        "\n",
        "## Boost的缺點：\n",
        "- **過擬合風險**：如果模型訓練過長，Boosting可能會過擬合訓練數據，尤其是在數據噪聲較多的情況下。\n",
        "- **計算成本較高**：由於Boosting需要多次迭代，並且每一輪模型的訓練是基於前一輪的錯誤，這會導致訓練時間較長。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1400f76d",
      "metadata": {
        "id": "1400f76d"
      },
      "source": [
        "## AdaBoost\n",
        "**AdaBoost**（Adaptive Boosting）是一種集成學習方法，屬於Boosting家族的算法。它通過將多個弱學習器（通常是簡單的模型，如決策樹）結合成一個強學習器來提高預測性能。AdaBoost的核心思想是根據前一輪模型的錯誤，對錯誤預測的樣本給予更高的權重，並在後續的模型中更加關注這些樣本，從而提升模型的準確度。\n",
        "\n",
        "### AdaBoost的工作原理：\n",
        "1. **初始化樣本權重**：\n",
        "   - 在訓練過程開始時，對所有訓練樣本賦予相同的權重。\n",
        "2. **訓練弱學習器**：\n",
        "   - 依次訓練多個弱學習器（例如簡單的決策樹）。每一輪的學習器會根據當前樣本的權重進行訓練。\n",
        "3. **計算每個弱學習器的錯誤率**：\n",
        "   - 計算每一輪學習器的錯誤率，即該學習器在當前加權樣本上的錯誤預測數量。\n",
        "4. **更新樣本權重**：\n",
        "   - 根據每個弱學習器的錯誤率，對錯誤分類的樣本賦予更高的權重，正確分類的樣本權重則降低。這樣，在下一輪訓練中，錯誤預測的樣本會得到更多的關注。\n",
        "5. **加權集成預測**：\n",
        "   - 最終的預測結果是每個弱學習器預測結果的加權和。每個學習器的權重與其準確性有關，錯誤較小的學習器權重較高。\n",
        "\n",
        "### AdaBoost的特點：\n",
        "1. **自適應性**：\n",
        "   - AdaBoost根據前一輪的錯誤來自適應調整樣本權重，使模型更加關注難以分類的樣本。\n",
        "2. **加強弱學習器**：\n",
        "   - 儘管每個弱學習器的預測能力可能較差，但通過加權集成多個弱學習器，最終的預測結果可以顯著提高。\n",
        "3. **簡單高效**：\n",
        "   - AdaBoost可以使用相對簡單的基礎模型（如決策樹）來實現強大的預測效果。\n",
        "4. **易於實現和理解**：\n",
        "   - 算法結構簡單，且具有較好的解釋性，容易理解和實現。\n",
        "\n",
        "### AdaBoost的優勢：\n",
        "- **提高預測準確度**：通過多輪迭代和加權集成，AdaBoost能夠顯著提高模型的預測準確度，尤其是在弱學習器的基礎上。\n",
        "- **減少過擬合風險**：與其他集成方法（如Bagging）相比，AdaBoost能夠集中學習錯誤樣本，減少過擬合的風險。\n",
        "- **高效訓練**：AdaBoost能夠在相對較少的訓練輪次中達到較好的效果，訓練過程相對高效。\n",
        "\n",
        "### AdaBoost的缺點：\n",
        "- **對噪聲敏感**：AdaBoost可能會對噪聲或異常值過於敏感，因為錯誤的樣本權重會在後續的訓練中被不成比例地加重。\n",
        "- **過度加強錯誤樣本**：如果訓練數據中有大量錯誤樣本或極端值，AdaBoost可能會過度關注這些樣本，導致過擬合。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df98b757",
      "metadata": {
        "id": "df98b757",
        "outputId": "6d663c36-64f9-4f6b-fd38-89a4b94917f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.23138628005981446\n",
            "score_time  :  0.03842940330505371\n",
            "test_balanced_accuracy  :  0.6591313448456306\n",
            "train_balanced_accuracy  :  0.7033550316259284\n",
            "test_roc_auc  :  0.8331526687598115\n",
            "train_roc_auc  :  0.9083435992736042\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "model = AdaBoostClassifier()\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f5db8c",
      "metadata": {
        "id": "c9f5db8c"
      },
      "source": [
        "## Gradient Boosting\n",
        "**Gradient Boosting**（梯度提升）是一種強大的集成學習方法，屬於Boosting家族。它通過結合多個弱學習器（通常是決策樹）來提升預測準確性。與其他Boosting算法不同，Gradient Boosting使用梯度下降法來逐步優化模型，將每一輪新模型的學習方向設置為當前模型誤差的負梯度。這樣逐步減少模型的預測誤差。\n",
        "\n",
        "### Gradient Boosting的工作原理：\n",
        "1. **初始化模型**：\n",
        "   - 開始時，訓練一個基礎模型，通常是對所有樣本預測其均值（回歸問題）或最常見的類別（分類問題）。\n",
        "2. **計算誤差（負梯度）**：\n",
        "   - 計算當前模型的預測誤差，這些誤差是目標函數對模型的梯度（即負梯度）。對於回歸問題，這些誤差是實際值與預測值之間的差；對於分類問題，這些誤差是對數損失的梯度。\n",
        "3. **擬合負梯度**：\n",
        "   - 根據誤差（負梯度），訓練一個新的模型（通常是一棵決策樹），使其擬合這些負梯度。\n",
        "4. **更新模型**：\n",
        "   - 將新模型的預測加到前一輪的模型中，並根據一定的學習率（步長）來更新最終的預測模型。\n",
        "5. **重複迭代**：\n",
        "   - 重複這個過程多次，每次都訓練一個新的模型來擬合前一輪模型的誤差，並逐步改進模型的預測能力。\n",
        "6. **最終預測**：\n",
        "   - 經過多輪迭代後，最終的預測是所有基礎模型的加權和，這些加權值由學習率控制。\n",
        "\n",
        "### Gradient Boosting的特點：\n",
        "1. **逐步減少誤差**：\n",
        "   - 每一輪的模型訓練都專注於最小化當前模型的誤差，這使得Gradient Boosting能夠逐步提升預測準確度。\n",
        "2. **基於梯度下降**：\n",
        "   - 利用梯度下降法，Gradient Boosting能夠在每一輪中找到最佳的擬合方向，從而有效地減少誤差。\n",
        "3. **強大的模型擬合能力**：\n",
        "   - 由於每個新的模型專注於擬合上一輪模型的誤差，Gradient Boosting能夠有效捕捉數據中的複雜模式，並具有較強的預測能力。\n",
        "4. **可以處理不同類型的問題**：\n",
        "   - 這種方法不僅能處理回歸問題，還能處理分類問題，並且具有良好的泛化能力。\n",
        "\n",
        "### Gradient Boosting的優勢：\n",
        "- **高準確度**：通過多次迭代和逐步減少誤差，Gradient Boosting通常能夠提供非常高的預測準確度。\n",
        "- **靈活性**：它可以使用不同的基礎學習器（如決策樹），並且支持多種損失函數，使其可以應對各種回歸和分類問題。\n",
        "- **強大的泛化能力**：經過適當的正則化，Gradient Boosting可以有效避免過擬合，並在大多數情況下具有較好的泛化能力。\n",
        "\n",
        "### Gradient Boosting的缺點：\n",
        "- **訓練時間較長**：由於每一輪的模型都是在前一輪模型的基礎上進行的，這使得Gradient Boosting的訓練過程比較耗時，特別是在大規模數據集上。\n",
        "- **對噪聲敏感**：如果數據中包含大量的噪聲或異常值，Gradient Boosting可能會過擬合這些噪聲，從而影響模型的預測效果。\n",
        "- **需要調整超參數**：為了獲得最佳性能，Gradient Boosting通常需要進行較為細致的超參數調整（例如學習率、樹的深度等）。\n",
        "\n",
        "### 常見的Gradient Boosting實現：\n",
        "1. **XGBoost**：\n",
        "   - XGBoost是Gradient Boosting的高效實現，具有許多優化，如支持並行計算、正則化等。它已經成為機器學習中最常用的算法之一。\n",
        "2. **LightGBM**：\n",
        "   - LightGBM是一個快速、分佈式的Gradient Boosting實現，特別適合大規模數據集。它使用直方圖算法來加速訓練，並且能夠有效處理大數據。\n",
        "3. **CatBoost**：\n",
        "   - CatBoost是另一個高效的Gradient Boosting實現，專注於提高類別特徵的處理能力。它對類別特徵的處理比XGBoost和LightGBM更為高效。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a50842a5",
      "metadata": {
        "id": "a50842a5",
        "outputId": "405d4f55-be34-4959-bae3-a86daa2561c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit_time  :  0.5595423221588135\n",
            "score_time  :  0.008278608322143555\n",
            "test_balanced_accuracy  :  0.6446546310832025\n",
            "train_balanced_accuracy  :  0.9127375038166239\n",
            "test_roc_auc  :  0.8207005494505493\n",
            "train_roc_auc  :  0.9916805982883918\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "run_cv(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5a49284",
      "metadata": {
        "id": "f5a49284"
      },
      "source": [
        "# XGBoost\n",
        "* https://xgboost.readthedocs.io/\n",
        "\n",
        "XGBoost（Extreme Gradient Boosting）是一種高效的機器學習算法，屬於梯度提升（Gradient Boosting）框架的擴展。它主要用於分類和回歸問題，因其在許多資料科學競賽中表現優異而廣受歡迎。\n",
        "\n",
        "## XGBoost的主要特點：\n",
        "\n",
        "1. **梯度提升（Gradient Boosting）**\n",
        "   - XGBoost通過組合多個弱學習器（通常是決策樹）來構建一個強學習器。每一個新模型都會試圖最小化前一個模型的誤差。\n",
        "2. **正則化**\n",
        "   - XGBoost加入了L1（Lasso）和L2（Ridge）正則化項，能有效避免過擬合，提升泛化能力。\n",
        "3. **處理缺失值**\n",
        "   - XGBoost具有自動處理缺失資料的能力，並且在訓練過程中能夠對缺失值進行適當的處理。\n",
        "4. **並行計算**\n",
        "   - XGBoost採用了並行計算來加速模型訓練，特別是在特徵選擇和樹結構優化方面，能顯著提高效率。\n",
        "5. **支持多種損失函數**\n",
        "   - XGBoost支持多種損失函數（如平方誤差、對數損失等），可以根據不同的任務選擇合適的損失函數。\n",
        "6. **交叉驗證和早停法**\n",
        "   - XGBoost提供了交叉驗證和早停法功能，幫助在訓練過程中選擇最佳的超參數並防止過擬合。\n",
        "7. **高效的樹結構優化**\n",
        "   - XGBoost採用了更高效的算法進行樹結構的分裂和優化，能進一步提高模型訓練的速度。\n",
        "\n",
        "由於這些特點，XGBoost被廣泛應用於各類資料分析任務，尤其在競賽、工業應用和大規模資料處理方面表現優異。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeea6588-3258-4764-9c0c-fa4b94e370ad",
      "metadata": {
        "id": "eeea6588-3258-4764-9c0c-fa4b94e370ad"
      },
      "outputs": [],
      "source": [
        "# ! pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00ea1a2",
      "metadata": {
        "id": "e00ea1a2",
        "outputId": "efd53b9f-f4f5-4a80-a9e7-e61b1dceb20c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 0, 0], shape=(1176,))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "model = XGBClassifier(n_estimators=100, learning_rate= 0.3)\n",
        "model = xgb.XGBClassifier(subsample=0.8)\n",
        "\n",
        "model.fit(data_input, data_target)\n",
        "# 使用訓練資料預測分類\n",
        "predicted = model.predict(data_input)\n",
        "predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f68e215-0b85-45bf-b25f-03ff9624d869",
      "metadata": {
        "id": "5f68e215-0b85-45bf-b25f-03ff9624d869"
      },
      "source": [
        "因為xgboost並非scikit-learn的內建套件，所以不完全相容於scikit-learn的功能\n",
        "\n",
        "譬如 cross_validate() 就無法正常執行\n",
        "\n",
        "```python\n",
        "score_type = ['balanced_accuracy','roc_auc']\n",
        "cv_scores = cross_validate(model, data_input, data_target, cv=5, n_jobs=5, return_train_score=True, scoring=score_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f50fc6f-8ae1-4fe6-9b55-320ffd592885",
      "metadata": {
        "id": "1f50fc6f-8ae1-4fe6-9b55-320ffd592885",
        "outputId": "f6a03f71-39d5-4942-bdf1-9ee3b41a0bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    train-merror-mean  train-merror-std  test-merror-mean  test-merror-std\n",
            "0            0.134141          0.003926          0.163264         0.015108\n",
            "1            0.131590          0.004105          0.156459         0.014547\n",
            "2            0.131590          0.005138          0.157310         0.015188\n",
            "3            0.128827          0.003668          0.150501         0.015505\n",
            "4            0.126700          0.003876          0.155615         0.015153\n",
            "5            0.126275          0.005818          0.153913         0.014098\n",
            "6            0.123724          0.004873          0.148810         0.014987\n",
            "7            0.122661          0.005785          0.145406         0.016213\n",
            "8            0.121598          0.005427          0.145398         0.011409\n",
            "9            0.120961          0.005093          0.147101         0.014798\n",
            "10           0.119472          0.006208          0.143696         0.012306\n",
            "11           0.119048          0.006197          0.142849         0.011495\n",
            "12           0.118622          0.004856          0.142001         0.013286\n",
            "13           0.118409          0.004757          0.141998         0.015275\n",
            "14           0.118197          0.003691          0.139445         0.014473\n",
            "15           0.116922          0.004251          0.140296         0.016926\n",
            "16           0.116072          0.004129          0.141998         0.016195\n",
            "17           0.113733          0.003983          0.142849         0.015749\n",
            "18           0.112883          0.005107          0.140296         0.014876\n",
            "19           0.111820          0.006503          0.141147         0.017644\n",
            "20           0.113521          0.004007          0.141143         0.016767\n",
            "21           0.111820          0.004740          0.141143         0.018803\n",
            "22           0.110757          0.004539          0.140288         0.019814\n",
            "23           0.109057          0.004508          0.138590         0.018630\n",
            "24           0.109057          0.004558          0.138590         0.018630\n",
            "25           0.107356          0.003023          0.137739         0.016998\n",
            "26           0.106293          0.003521          0.139437         0.018757\n",
            "27           0.105444          0.004365          0.138590         0.017216\n",
            "28           0.104381          0.003922          0.139441         0.018791\n",
            "29           0.102893          0.004762          0.141143         0.019373\n",
            "30           0.100767          0.004147          0.138594         0.018072\n",
            "31           0.100554          0.003638          0.138594         0.016610\n",
            "32           0.098641          0.004152          0.136891         0.014943\n",
            "33           0.098641          0.004042          0.136040         0.014342\n",
            "34           0.098216          0.003020          0.135189         0.015169\n",
            "35           0.095878          0.004262          0.136040         0.013828\n",
            "36           0.094602          0.003845          0.135193         0.011075\n",
            "37           0.092902          0.005360          0.132640         0.011989\n",
            "38           0.092476          0.004744          0.136040         0.010899\n",
            "39           0.092477          0.005498          0.133491         0.011442\n",
            "40           0.090776          0.005050          0.132636         0.012816\n",
            "Best iteration: 40\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 創建 XGBoost DMatrix，這是 XGBoost 特有的數據結構\n",
        "train_data = xgb.DMatrix(data_input, label=data_target)\n",
        "\n",
        "# 設置模型參數\n",
        "params = {\n",
        "    'objective': 'multi:softmax',  # 目標是多類分類\n",
        "    'num_class': 3,  # 有三個類別\n",
        "    'max_depth': 3,  # 決策樹的最大深度\n",
        "    'eta': 0.1,  # 學習率\n",
        "    'eval_metric': 'merror'  # 用來衡量模型的準確度\n",
        "}\n",
        "\n",
        "# 設置交叉驗證的參數\n",
        "num_round = 100  # 訓練的迭代次數\n",
        "cv_results = xgb.cv(\n",
        "    params,               # 參數設置\n",
        "    train_data,           # 訓練數據\n",
        "    num_round,            # 訓練輪數\n",
        "    nfold=5,              # 進行 5-fold 交叉驗證\n",
        "    metrics='merror',     # 使用錯誤率 (misclassification error) 作為評估指標\n",
        "    early_stopping_rounds=10,  # 早停策略，10輪內如果性能未提升則停止訓練\n",
        "    as_pandas=True,       # 返回 pandas DataFrame 格式的結果\n",
        "    seed=42               # 隨機種子\n",
        ")\n",
        "\n",
        "# 顯示交叉驗證結果\n",
        "print(cv_results)\n",
        "\n",
        "# 找出最佳的迭代次數\n",
        "best_iteration = cv_results['test-merror-mean'].idxmin()\n",
        "print(f\"Best iteration: {best_iteration}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5880d1dd-9dd5-4e46-80cd-a4c541d3593a",
      "metadata": {
        "id": "5880d1dd-9dd5-4e46-80cd-a4c541d3593a"
      },
      "source": [
        "# Stacking\n",
        "\n",
        "**Stacking**（堆疊）是一種集成學習方法，旨在將多個不同的基礎學習器結合起來，通過將各個模型的預測結果作為新特徵來訓練最終的預測模型。這種方法通常會用到兩層模型：第一層由多個基礎學習器組成，第二層則是學習如何將第一層的預測結果結合起來。\n",
        "\n",
        "## Stacking的工作原理：\n",
        "\n",
        "1. **基礎學習器訓練**：\n",
        "   - 在第一層，選擇多個不同的基礎學習器（如決策樹、支持向量機、邏輯回歸等），並用相同的訓練數據訓練這些模型。每個基礎學習器會獨立預測訓練樣本。\n",
        "2. **生成新的訓練數據**：\n",
        "   - 將每個基礎學習器的預測結果（對於每個樣本）作為新的特徵，並構成新的訓練數據集。這些新特徵將成為第二層模型的輸入。\n",
        "3. **第二層模型訓練**：\n",
        "   - 使用新生成的特徵來訓練第二層的學習器（通常是線性模型，如邏輯回歸或簡單的線性回歸）。這一層模型學習如何根據第一層模型的預測結果來做出最終的預測。\n",
        "4. **最終預測**：\n",
        "   - 在預測階段，首先通過第一層的基礎學習器得到各自的預測結果，然後將這些結果作為新特徵輸入到第二層模型中，最終得出最終預測結果。\n",
        "\n",
        "## Stacking的特點：\n",
        "1. **多樣性**：\n",
        "   - Stacking方法使用多種不同的基礎學習器，因此能夠結合它們的優勢，提高預測的穩定性和準確度。\n",
        "2. **兩層結構**：\n",
        "   - Stacking分為兩層：第一層由多個基礎學習器組成，第二層則是學習如何將這些基礎學習器的結果進行組合。\n",
        "3. **靈活性**：\n",
        "   - 可以根據不同的問題和需求選擇適合的基礎學習器和第二層模型，這使得Stacking具有很高的靈活性。\n",
        "4. **非線性組合**：\n",
        "   - 第二層的模型可以學習到基礎學習器預測結果之間的複雜關係，從而提供比單一模型更強的預測能力。\n",
        "\n",
        "## Stacking的優勢：\n",
        "- **提高準確度**：通過集成多個基礎學習器的預測，Stacking通常能夠提供比單一模型更高的預測準確度。\n",
        "- **捕捉更多樣本模式**：多個基礎學習器能夠捕捉數據中的不同模式，從而提高模型的泛化能力。\n",
        "- **減少過擬合**：由於第二層模型在學習如何組合基礎學習器的預測結果，Stacking有時能夠減少過擬合的風險。\n",
        "\n",
        "## Stacking的缺點：\n",
        "- **計算成本較高**：由於需要訓練多個基礎學習器以及第二層模型，Stacking的計算開銷通常比較大。\n",
        "- **需要更多的數據**：為了訓練第二層模型，Stacking通常需要較多的數據，尤其是在基礎學習器較多的情況下。\n",
        "- **較難調整**：由於Stacking的結構較為複雜，超參數調整可能需要更多的時間和精力。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "466a892b",
      "metadata": {
        "id": "466a892b",
        "outputId": "506ecd7b-1558-443e-cec6-3cd7c401ac00"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;Tree&#x27;, DecisionTreeClassifier()),\n",
              "                               (&#x27;KNN&#x27;, KNeighborsClassifier()),\n",
              "                               (&#x27;LogisticRegression&#x27;, LogisticRegression())],\n",
              "                   final_estimator=SVC())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>StackingClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.StackingClassifier.html\">?<span>Documentation for StackingClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></div></label><div class=\"sk-toggleable__content \"><pre>StackingClassifier(estimators=[(&#x27;Tree&#x27;, DecisionTreeClassifier()),\n",
              "                               (&#x27;KNN&#x27;, KNeighborsClassifier()),\n",
              "                               (&#x27;LogisticRegression&#x27;, LogisticRegression())],\n",
              "                   final_estimator=SVC())</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><label>Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>DecisionTreeClassifier()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><label>KNN</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a></div></label><div class=\"sk-toggleable__content \"><pre>KNeighborsClassifier()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><label>LogisticRegression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content \"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label  sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label  sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content \"><pre>SVC()</pre></div> </div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "StackingClassifier(estimators=[('Tree', DecisionTreeClassifier()),\n",
              "                               ('KNN', KNeighborsClassifier()),\n",
              "                               ('LogisticRegression', LogisticRegression())],\n",
              "                   final_estimator=SVC())"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "\n",
        "estimators_list=[\n",
        "    ('Tree', DecisionTreeClassifier() ),\n",
        "    ('KNN', KNeighborsClassifier() ),\n",
        "    ('LogisticRegression', LogisticRegression() ),\n",
        "]\n",
        "\n",
        "model = StackingClassifier(\n",
        "    estimators=estimators_list,\n",
        "    final_estimator=SVC())\n",
        "\n",
        "model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}